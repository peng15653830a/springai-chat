# AI智能聊天系统 - 系统架构设计文档

> 版本：v3.0  
> 更新时间：2025年9月  
> 基于重构后的多AI提供商响应式架构

## 1. 系统整体架构

### 1.1 架构概览
```
┌─────────────────┐    HTTP + SSE        ┌─────────────────────────┐
│   Vue3前端      │ ←─────────────────→ │  Spring Boot + WebFlux │
│   - Element Plus│                      │  响应式后端服务         │
│   - 原生Markdown│                      │                         │
│   - EventSource │                      │                         │
└─────────────────┘                      └─────────────────────────┘
                                                    │
                                         ┌──────────┼──────────┐
                                         │          │          │
                               ┌─────────▼──┐ ┌─────▼───┐ ┌───▼─────┐
                               │  多AI提供商 │ │ Tavily  │ │PostgreSQL│
                               │OpenAI/Kimi │ │搜索API  │ │ + MyBatis│
                               │DeepSeek等  │ │         │ │         │
                               └────────────┘ └─────────┘ └─────────┘
```

### 1.2 核心架构特征
- **响应式编程**：基于Spring WebFlux + Project Reactor
- **多AI提供商**：统一ModelProvider接口，支持OpenAI、Kimi、DeepSeek、通义千问
- **模块化设计**：遵循SOLID原则，职责清晰分离
- **流式处理**：SSE + Reactive Streams实现实时对话
- **配置驱动**：统一配置属性管理

## 2. 技术架构

### 2.1 后端技术栈
- **框架**：Spring Boot 2.7.18 + Spring WebFlux
- **响应式**：Project Reactor (Mono/Flux)
- **数据库**：PostgreSQL 14+
- **ORM**：MyBatis 3.5.13
- **HTTP客户端**：WebClient (响应式) + Apache HttpClient
- **实时通信**：Server-Sent Events + Reactive Streams
- **配置管理**：Spring Boot Configuration Properties
- **工具库**：Lombok, Jackson

### 2.2 前端技术栈
- **框架**：Vue 3 + Composition API
- **构建工具**：Vite 4.5+
- **UI组件**：Element Plus 2.4+
- **状态管理**：Pinia 2.1+
- **HTTP客户端**：Axios 1.5+
- **实时通信**：原生EventSource API
- **Markdown渲染**：原生实现（已弃用v-md-editor）
- **工具库**：@vueuse/core

### 2.3 架构模式
- **三层架构**：Controller → Service → Repository
- **策略模式**：AI提供商选择策略
- **工厂模式**：ModelProvider工厂
- **注册表模式**：提供商注册管理
- **组件模式**：聊天功能模块化

## 3. 数据库设计

### 3.1 PostgreSQL表结构

#### 用户表 (users)
```sql
CREATE TABLE users (
    id BIGSERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE,
    nickname VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- 更新时间触发器
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_users_updated_at BEFORE UPDATE
ON users FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

#### 对话会话表 (conversations)
```sql
CREATE TABLE conversations (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    title VARCHAR(200),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
);

CREATE INDEX idx_conversations_user_id ON conversations(user_id);
CREATE INDEX idx_conversations_created_at ON conversations(created_at DESC);

CREATE TRIGGER update_conversations_updated_at BEFORE UPDATE
ON conversations FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

#### 消息表 (messages)
```sql
CREATE TABLE messages (
    id BIGSERIAL PRIMARY KEY,
    conversation_id BIGINT NOT NULL,
    role VARCHAR(20) NOT NULL CHECK (role IN ('user', 'assistant')),
    content TEXT NOT NULL,
    thinking TEXT,
    search_results JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_messages_conversation_id ON messages(conversation_id);
CREATE INDEX idx_messages_created_at ON messages(created_at);
CREATE INDEX idx_messages_search_results ON messages USING GIN(search_results);
```

#### AI模型表 (ai_models)
```sql
CREATE TABLE ai_models (
    id BIGSERIAL PRIMARY KEY,
    provider_name VARCHAR(50) NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    display_name VARCHAR(100) NOT NULL,
    description TEXT,
    max_tokens INTEGER DEFAULT 4096,
    supports_streaming BOOLEAN DEFAULT true,
    supports_search BOOLEAN DEFAULT true,
    supports_thinking BOOLEAN DEFAULT false,
    is_available BOOLEAN DEFAULT true,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(provider_name, model_name)
);

CREATE INDEX idx_ai_models_provider ON ai_models(provider_name);
CREATE INDEX idx_ai_models_available ON ai_models(is_available);
```

#### 用户模型偏好表 (user_model_preferences)
```sql
CREATE TABLE user_model_preferences (
    id BIGSERIAL PRIMARY KEY,
    user_id BIGINT NOT NULL,
    provider_name VARCHAR(50) NOT NULL,
    model_name VARCHAR(100) NOT NULL,
    is_default BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    UNIQUE(user_id, provider_name, model_name)
);

CREATE INDEX idx_user_model_preferences_user_id ON user_model_preferences(user_id);
CREATE INDEX idx_user_model_preferences_default ON user_model_preferences(user_id, is_default);
```

### 3.2 实体类设计

```java
// 使用PostgreSQL的BIGSERIAL对应Java的Long类型
@Data
public class User {
    private Long id;
    private String username;
    private String email;
    private String nickname;
    private LocalDateTime createdAt;
    private LocalDateTime updatedAt;
}

@Data
public class Message {
    private Long id;
    private Long conversationId;
    private String role;
    private String content;
    private String thinking;
    private String searchResults; // 存储JSON字符串
    private LocalDateTime createdAt;
}
```

## 4. 核心模块设计

### 4.1 AI聊天服务架构

```java
/**
 * 重构后的AI聊天服务 - 职责简化为流程协调
 */
@Slf4j
@Service
@RequiredArgsConstructor
public class AiChatServiceImpl implements AiChatService {
    
    private final ChatStreamingProperties streamingProperties;
    private final SearchService searchService;
    private final ModelSelector modelSelector;
    private final PromptBuilder promptBuilder;
    private final ChatErrorHandler errorHandler;
    private final ModelProviderFactory modelProviderFactory;
    
    @Override
    public Flux<SseEventResponse> streamChatWithModel(
            Long conversationId, String message, boolean searchEnabled,
            boolean deepThinking, Long userId, String provider, String model) {
        
        return Mono.fromCallable(() -> {
            // 1. 模型选择
            ModelSelection selection = modelSelector.selectModel(provider, model, userId);
            
            // 2. 构建提示词
            return promptBuilder.buildPrompt(conversationId, message, searchEnabled);
        })
        .flatMapMany(prompt -> {
            // 3. 获取AI提供商
            ModelProvider modelProvider = modelProviderFactory.getProvider(selection.provider());
            
            // 4. 构建请求
            ChatRequest request = ChatRequest.builder()
                .conversationId(conversationId)
                .message(prompt)
                .searchEnabled(searchEnabled)
                .deepThinking(deepThinking)
                .model(selection.model())
                .build();
                
            // 5. 流式响应处理
            return modelProvider.streamChat(request);
        })
        .onErrorResume(errorHandler::handleChatError);
    }
}
```

### 4.2 AI提供商架构

#### 统一提供商接口
```java
public interface ModelProvider {
    /**
     * 流式聊天
     */
    Flux<SseEventResponse> streamChat(ChatRequest request);
    
    /**
     * 获取可用模型列表
     */
    List<ModelInfo> getAvailableModels();
    
    /**
     * 检查模型是否可用
     */
    boolean isModelAvailable(String modelName);
    
    /**
     * 获取提供商名称
     */
    String getProviderName();
}
```

#### 提供商实现示例
```java
@Service
@RequiredArgsConstructor
public class OpenaiModelProvider implements ModelProvider {
    
    private final WebClient webClient;
    private final ObjectMapper objectMapper;
    
    @Override
    public Flux<SseEventResponse> streamChat(ChatRequest request) {
        return webClient.post()
            .uri("/chat/completions")
            .header("Authorization", "Bearer " + apiKey)
            .bodyValue(buildRequestBody(request))
            .retrieve()
            .bodyToFlux(String.class)
            .map(this::parseStreamResponse)
            .map(this::toSseEventResponse);
    }
    
    @Override
    public String getProviderName() {
        return "openai";
    }
}
```

#### 工厂模式管理
```java
@Component
@RequiredArgsConstructor
public class ModelProviderFactory {
    
    private final ProviderRegistry providerRegistry;
    private final ProviderSelectionStrategy selectionStrategy;
    
    public ModelProvider getProvider(String providerName) {
        return providerRegistry.getProvider(providerName)
            .orElseThrow(() -> new ProviderNotFoundException(providerName));
    }
    
    public ModelProvider selectProvider(String providerName, String modelName) {
        List<ModelProvider> availableProviders = providerRegistry.findAllAvailable();
        return selectionStrategy.selectProvider(availableProviders, providerName, modelName)
                .orElseThrow(() -> new IllegalStateException("没有找到匹配的模型提供者"));
    }
}
```

### 4.3 聊天功能模块化

#### 提示词构建器
```java
@Service
@RequiredArgsConstructor
public class DefaultPromptBuilder implements PromptBuilder {
    
    private final MessageService messageService;
    private final SearchService searchService;
    
    @Override
    public Mono<String> buildPrompt(Long conversationId, String userMessage, boolean searchEnabled) {
        // 获取历史消息
        Mono<List<Message>> historyMono = messageService.getConversationHistoryAsync(conversationId);
        
        // 获取搜索上下文
        Mono<String> searchContextMono = searchEnabled ? 
                searchService.performSearchWithEvents(userMessage, true)
                        .map(result -> searchService.formatSearchResults(result.getSearchResults())) :
                Mono.just("");
        
        return Mono.zip(historyMono, searchContextMono)
                .map(tuple -> buildPromptFromMessages(tuple.getT1(), userMessage, tuple.getT2()));
    }
}
```

#### 错误处理器
```java
@Service
@RequiredArgsConstructor
public class DefaultChatErrorHandler implements ChatErrorHandler {
    
    @Override
    public Flux<SseEventResponse> handleChatError(Throwable error) {
        log.error("聊天服务发生错误", error);
        
        ErrorType errorType = classifyError(error);
        String friendlyMessage = generateFriendlyErrorMessage(errorType);
        
        return Flux.just(SseEventResponse.createErrorEvent(friendlyMessage));
    }
    
    private ErrorType classifyError(Throwable error) {
        if (error instanceof TimeoutException) return ErrorType.TIMEOUT_ERROR;
        if (error instanceof ConnectException) return ErrorType.NETWORK_ERROR;
        // ... 更多错误分类
        return ErrorType.UNKNOWN_ERROR;
    }
}
```

## 5. 配置管理设计

### 5.1 配置属性类

#### 搜索配置
```java
@Data
@Component
@ConfigurationProperties(prefix = "search")
public class SearchProperties {
    
    private boolean enabled = true;
    private Tavily tavily = new Tavily();
    
    @Data
    public static class Tavily {
        private String apiKey = "";
        private String baseUrl = "https://api.tavily.com/search";
    }
}
```

#### ModelScope配置
```java
@Data
@Component
@ConfigurationProperties(prefix = "spring.ai.openai")
public class ModelScopeProperties {
    
    private String apiKey;
    private String baseUrl = "https://api-inference.modelscope.cn/v1";
    private Chat chat = new Chat();
    
    @Data
    public static class Chat {
        private Options options = new Options();
        
        @Data
        public static class Options {
            private String model = "Qwen/Qwen3-235B-A22B-Thinking-2507";
            private double temperature = 0.7;
            private int maxTokens = 2000;
            private boolean enableThinking = true;
            private int thinkingBudget = 50000;
        }
    }
}
```

### 5.2 应用配置文件

```yaml
# application.yml
spring:
  # PostgreSQL配置
  datasource:
    url: jdbc:postgresql://localhost:5432/ai_chat
    username: ${DB_USERNAME:ai_chat_user}
    password: ${DB_PASSWORD:password}
    driver-class-name: org.postgresql.Driver
    
  # AI配置
  ai:
    openai:
      api-key: ${OPENAI_API_KEY:}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
      chat:
        options:
          model: gpt-3.5-turbo
          temperature: 0.7
          thinking-budget: 50000

# 搜索配置
search:
  enabled: true
  tavily:
    api-key: ${TAVILY_API_KEY:}
    base-url: https://api.tavily.com/search

# 聊天流式配置
chat:
  streaming:
    response-timeout: PT2M
    buffer-size: 8192
    
# MyBatis配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.example.entity
  configuration:
    map-underscore-to-camel-case: true
```

## 6. API接口设计

### 6.1 流式聊天接口

```java
@RestController
@RequestMapping("/api/chat")
@RequiredArgsConstructor
public class ChatController {
    
    private final AiChatService aiChatService;
    
    @GetMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<SseEventResponse> streamChat(
            @Valid @ModelAttribute StreamChatRequest request) {
        
        return aiChatService.streamChatWithModel(
            request.getConversationId(),
            request.getMessage(), 
            request.isSearchEnabled(),
            request.isDeepThinking(),
            request.getUserId(),
            request.getProvider(),
            request.getModel()
        );
    }
}
```

### 6.2 模型管理接口

```java
@RestController
@RequestMapping("/api/models")
@RequiredArgsConstructor
public class ModelController {
    
    @GetMapping("/providers")
    public List<ProviderInfo> getAvailableProviders() {
        return modelManagementService.getAvailableProviders();
    }
    
    @GetMapping("/user-preference")
    public UserModelPreferenceDto getUserModelPreference(@RequestParam Long userId) {
        return modelManagementService.getUserDefaultModel(userId);
    }
}
```

## 7. 前端架构设计

### 7.1 组件架构
```
src/
├── components/
│   ├── chat/
│   │   ├── ChatContainer.vue      # 聊天容器
│   │   ├── MessageList.vue        # 消息列表
│   │   ├── MessageInput.vue       # 输入组件
│   │   └── MarkdownRenderer.vue   # 原生Markdown渲染
│   ├── conversation/
│   │   └── ConversationList.vue   # 对话列表
│   └── model/
│       └── ModelSelector.vue      # 模型选择器
├── stores/
│   ├── chat.js                    # 聊天状态
│   ├── conversation.js            # 对话状态
│   └── model.js                   # 模型状态
└── api/
    ├── chat.js                    # 聊天API
    ├── conversation.js            # 对话API
    └── model.js                   # 模型API
```

### 7.2 Markdown渲染方案

```vue
<!-- MarkdownRenderer.vue - 原生实现替代v-md-editor -->
<template>
  <div class="markdown-content" v-html="renderedHtml"></div>
</template>

<script setup>
import { computed } from 'vue'
import { marked } from 'marked'
import hljs from 'highlight.js'

const props = defineProps({
  content: String
})

// 配置marked
marked.setOptions({
  highlight: function(code, lang) {
    if (lang && hljs.getLanguage(lang)) {
      return hljs.highlight(code, { language: lang }).value
    }
    return hljs.highlightAuto(code).value
  },
  breaks: true,
  gfm: true
})

const renderedHtml = computed(() => {
  return marked(props.content || '')
})
</script>
```

### 7.3 SSE连接管理

```javascript
// stores/chat.js
import { defineStore } from 'pinia'

export const useChatStore = defineStore('chat', {
  state: () => ({
    messages: [],
    isStreaming: false,
    currentStreamMessage: '',
    sseConnection: null
  }),
  
  actions: {
    // 发起流式聊天
    async startStreamChat(request) {
      this.isStreaming = true
      this.currentStreamMessage = ''
      
      const sseUrl = `/api/chat/stream?${new URLSearchParams(request)}`
      this.sseConnection = new EventSource(sseUrl)
      
      this.sseConnection.onmessage = (event) => {
        const data = JSON.parse(event.data)
        this.handleSSEEvent(data)
      }
      
      this.sseConnection.onerror = () => {
        this.handleSSEError()
      }
    },
    
    handleSSEEvent(data) {
      switch(data.type) {
        case 'content':
          this.currentStreamMessage += data.data
          break
        case 'end':
          this.finishStreaming()
          break
      }
    },
    
    closeSSEConnection() {
      if (this.sseConnection) {
        this.sseConnection.close()
        this.sseConnection = null
      }
    }
  }
})
```

## 8. 性能优化策略

### 8.1 数据库优化
- **连接池**：使用HikariCP连接池
- **索引优化**：关键查询字段添加索引
- **分页查询**：避免全表扫描
- **JSON字段**：PostgreSQL JSONB高效存储搜索结果

### 8.2 响应式优化
- **背压处理**：Flux背压机制防止内存溢出
- **连接池复用**：WebClient连接池复用
- **缓存策略**：模型信息缓存，搜索结果缓存
- **流式处理**：减少内存占用

### 8.3 前端优化
- **虚拟滚动**：消息列表虚拟滚动
- **懒加载**：图片和组件懒加载
- **防抖节流**：输入框防抖优化
- **原生Markdown**：轻量级原生渲染替代重型编辑器

## 9. 安全架构

### 9.1 API安全
- **密钥管理**：环境变量或密钥管理服务
- **输入验证**：@Valid注解 + 自定义验证器
- **SQL注入防护**：MyBatis参数化查询
- **XSS防护**：前端输入过滤和转义

### 9.2 数据安全
- **传输加密**：HTTPS/TLS
- **敏感数据**：不记录API密钥等敏感信息
- **访问控制**：用户权限验证
- **数据脱敏**：日志中敏感信息脱敏

## 10. 监控与运维

### 10.1 应用监控
```yaml
# actuator配置
management:
  endpoints:
    web:
      exposure:
        include: health,metrics,info,prometheus
  metrics:
    export:
      prometheus:
        enabled: true
```

### 10.2 关键指标
- **响应时间**：API响应时间分位数
- **并发连接**：SSE连接数统计
- **错误率**：按AI提供商分类的错误率
- **资源使用**：内存、CPU使用率
- **业务指标**：对话数量、用户活跃度

---

**文档状态**：v3.0 完成  
**基于架构**：多AI提供商 + PostgreSQL + 响应式编程  
**相关文档**：[开发指南](../development/开发指南.md) | [部署文档](../deployment/部署运维文档.md)