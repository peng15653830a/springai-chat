server:
  port: 8080
  servlet:
    encoding:
      charset: UTF-8
      enabled: true
      force: true

spring:
  application:
    name: ai-chat

  # 数据源配置
  datasource:
    # PostgreSQL数据库配置
    driver-class-name: org.postgresql.Driver
    url: jdbc:postgresql://localhost:5432/ai_chat
    username: root
    password: xupeng2016
  
  # JPA配置
  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false
    database-platform: org.hibernate.dialect.PostgreSQLDialect

  # SQL初始化配置 (暂时禁用，手动初始化)
  sql:
    init:
      mode: never
      encoding: UTF-8
  
  # AI配置 - 保持原有Spring AI配置兼容性
  ai:
    openai:
      api-key: ${OPENAI_API_KEY:your_api_key}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com}
      chat:
        options:
          model: ${OPENAI_MODEL:gpt-3.5-turbo}
          temperature: 0.7
          max-tokens: 4192

# 多模型配置
ai:
  models:
    # 是否启用多模型功能
    enabled: ${MULTI_MODEL_ENABLED:true}
    
    # 默认模型配置
    default-provider: ${DEFAULT_PROVIDER:qwen}
    default-model: ${DEFAULT_MODEL:Qwen/Qwen3-235B-A22B-Thinking-2507}
    
    # 全局默认参数
    defaults:
      temperature: 0.7
      max-tokens: 4192
      timeout-ms: 30000
      thinking-budget: 50000
      stream-enabled: true
    
    # 模型提供者配置
    providers:
      # 通义千问配置
      qwen:
        enabled: ${QWEN_ENABLED:true}
        display-name: "通义千问"
        api-key: ${QWEN_API_KEY:your_api_key}
        base-url: ${QWEN_BASE_URL:https://api-inference.modelscope.cn}
        connect-timeout-ms: 10000
        read-timeout-ms: 30000
        models:
          - name: "Qwen/Qwen3-235B-A22B-Thinking-2507"
            display-name: "通义千问-推理版"
            max-tokens: 4192
            temperature: 0.7
            supports-thinking: true
            supports-streaming: true
            enabled: true
            sort-order: 1
            thinking-budget: 50000
      
      # OpenAI配置  
      openai:
        enabled: ${OPENAI_ENABLED:true}
        display-name: "OpenAI"
        api-key: ${OPENAI_API_KEY:your_api_key}
        base-url: ${OPENAI_API_BASE_URL:https://api-inference.modelscope.cn}
        connect-timeout-ms: 10000
        read-timeout-ms: 30000
        models:
          - name: "openai-mirror/gpt-oss-120b"
            display-name: "gpt-oss-120b"
            max-tokens: 4192
            temperature: 0.7
            supports-thinking: false
            supports-streaming: true
            enabled: true
            sort-order: 1
      
      # Kimi2配置
      kimi2:
        enabled: ${KIMI2_ENABLED:true}
        display-name: "Kimi2"
        api-key: ${KIMI2_API_KEY:your_api_key}
        base-url: ${KIMI2_BASE_URL:https://api-inference.modelscope.cn}
        connect-timeout-ms: 10000
        read-timeout-ms: 30000
        models:
          - name: "moonshotai/Kimi-K2-Instruct"
            display-name: "kimi2"
            max-tokens: 4192
            temperature: 0.7
            supports-thinking: false
            supports-streaming: true
            enabled: true
            sort-order: 1
      
      # DeepSeek配置
      DeepSeek:
        enabled: ${DEEPSEEK_ENABLED:true}
        display-name: "DeepSeek"
        api-key: ${DEEPSEEK_API_KEY:your_api_key}
        base-url: ${DEEPSEEK_BASE_URL:https://api.deepseek.com}
        connect-timeout-ms: 10000
        read-timeout-ms: 30000
        models:
          - name: "deepseek-chat"
            display-name: "DeepSeek-V3.1"
            max-tokens: 4192
            temperature: 0.7
            supports-thinking: false
            supports-streaming: true
            enabled: true
            sort-order: 1
      
      # 长城大模型配置
      greatwall:
        enabled: ${GREATWALL_ENABLED:true}
        display-name: "长城大模型"
        api-key: ${GREATWALL_API_KEY:your_greatwall_key}
        base-url: ${GREATWALL_BASE_URL:https://agent.ai.sinopec.com/aicoapi/gateway/v2/chatbot/api_run/1745897196_38b0ccad-62d4-49d2-a44a-8da43d8ab344}
        connect-timeout-ms: 15000
        read-timeout-ms: 60000
        models:
          - name: "greatwall-deepseek-v3"
            display-name: "长城大模型-DeepSeek-V3"
            max-tokens: 4096
            temperature: 0.7
            supports-thinking: false
            supports-streaming: true
            enabled: true
            sort-order: 1
            non-standard-api: true
            tpuid-prefix: "guest"

# 长城大模型SSL配置
# 注意：跳过SSL验证仅应在开发环境使用，生产环境应配置正确的SSL证书
greatwall:
  ssl:
    # 是否跳过SSL证书验证（开发环境：true，生产环境：false）
    skip-verification: ${GREATWALL_SSL_SKIP_VERIFICATION:true}
  
  # 异步任务配置
  task:
    execution:
      pool:
        core-size: 5
        max-size: 20
        queue-capacity: 100
        thread-name-prefix: "ai-chat-"

# MyBatis配置
mybatis:
  mapper-locations: classpath:mapper/*.xml
  type-aliases-package: com.example.entity
  configuration:
    map-underscore-to-camel-case: true
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
    cache-enabled: true
    lazy-loading-enabled: true

# 日志配置
logging:
  level:
    com.example: DEBUG
    org.springframework.ai: DEBUG
    org.mybatis: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# 搜索服务配置
search:
  tavily:
    api-key: ${TAVILY_API_KEY:your_api_key}
    base-url: ${TAVILY_BASE_URL:https://api.tavily.com/search}
  enabled: ${SEARCH_ENABLED:true}

# 应用配置
app:
  chat:
    max-history-size: 20
    response-timeout: 300s
    sse-timeout: 300s
    streaming:
      chunk-size: 50
      buffer-timeout: 100ms
      heartbeat-interval: 30s
    error:
      retry-attempts: 3
      retry-delay: 1000ms